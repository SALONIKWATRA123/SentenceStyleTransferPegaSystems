{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e42d637",
   "metadata": {},
   "source": [
    "# Sentence Style Transfer: T5 vs GPT-4o Mini\n",
    "\n",
    "This notebook demonstrates English sentence style transfer using a fine-tuned T5 model and OpenAI GPT-4o Mini. It covers informal-to-formal and formal-to-informal transfer, BLEU score evaluation, and LLM-based judging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9de4b6",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Style transfer is the task of rewriting text from one style (e.g., informal) to another (e.g., formal) while preserving meaning. This notebook compares a fine-tuned T5 model and GPT-4o Mini for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc8896",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports\n",
    "\n",
    "Install and import all required libraries for model loading, inference, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26228146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: dotenv in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: openai in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (2.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: tqdm>4 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: transformers in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (4.57.6)\n",
      "Requirement already satisfied: requests in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.36.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install dotenv\n",
    "!pip install openai\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b003ce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (1.13.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: networkx in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.0\n",
      "    Uninstalling torch-1.13.0:\n",
      "      Successfully uninstalled torch-1.13.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.0 requires torch==1.13.0, but you have torch 2.2.2 which is incompatible.\n",
      "ctgan 0.6.0 requires torch<2,>=1.8.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e12b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (4.57.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.36.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/salonik/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4d807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salonik/Documents/SentenceStyleTransferPegaSystems/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/salonik/Documents/SentenceStyleTransferPegaSystems/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if running in Colab or a fresh environment\n",
    "# !pip install transformers openai nltk python-dotenv\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ea1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "4.57.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e29bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.29.2\n",
      "Uninstalling transformers-4.29.2:\n",
      "  Successfully uninstalled transformers-4.29.2\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/52/f3/ac976fa8e305c9e49772527e09fbdc27cc6831b8a2f6b6063406626be5dd/transformers-5.0.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: filelock in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<2.0,>=1.3.0 from https://files.pythonhosted.org/packages/54/89/bfbfde252d649fae8d5f09b14a2870e5672ed160c1a6629301b3e5302621/huggingface_hub-1.3.7-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<=0.23.0,>=0.22.0 from https://files.pythonhosted.org/packages/2e/47/174dca0502ef88b28f1c9e06b73ce33500eedfac7a7692108aec220464e7/tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Obtaining dependency information for typer-slim from https://files.pythonhosted.org/packages/c8/0a/4aca634faf693e33004796b6cee0ae2e1dba375a800c16ab8d3eff4bb800/typer_slim-0.21.1-py3-none-any.whl.metadata\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/e8/00/374c0c068e30cd31f1e1b46b4b5738168ec79e7689ca82ee93ddfea05109/safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/01/c9/97cc5aae1648dcb851958a3ddf73ccd7dbe5650d95203ecb4d7720b4cdbf/fsspec-2026.1.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.2.0 from https://files.pythonhosted.org/packages/7f/8c/c5becfa53234299bc2210ba314eaaae36c2875e0045809b82e40a9544f0c/hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from typer-slim->transformers) (8.0.4)\n",
      "Requirement already satisfied: anyio in /Users/salonik/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/salonik/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/salonik/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/salonik/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/salonik/anaconda3/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Downloading transformers-5.0.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.3.7-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: typer-slim, shellingham, safetensors, hf-xet, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.12.0 requires huggingface-hub<1.0.0,>=0.11.0, but you have huggingface-hub 1.3.7 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2026.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2026.1.0 hf-xet-1.2.0 huggingface-hub-1.3.7 safetensors-0.7.0 shellingham-1.5.4 tokenizers-0.22.2 transformers-5.0.0 typer-slim-0.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b21be4",
   "metadata": {},
   "source": [
    "## 3. Load Models\n",
    "\n",
    "Load the fine-tuned T5 model and set up the GPT-4o Mini API for style transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned T5 model\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Make sure this is called before accessing the API key\n",
    "import openai\n",
    "model_name = 'prithivida/informal_to_formal_styletransfer'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Set up OpenAI API key (ensure your .env file is set or set the key here)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print('OpenAI API Key loaded:', openai.api_key is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a5085",
   "metadata": {},
   "source": [
    "## 4. Define Helper Functions\n",
    "\n",
    "Define functions for style transfer, BLEU score calculation, and LLM-based judging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdf4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_style_transfer(sentence, direction=\"informal_to_formal\", max_length=64):\n",
    "    if direction == \"informal_to_formal\":\n",
    "        input_text = f\"transfer informal to formal: {sentence}\"\n",
    "    else:\n",
    "        input_text = f\"transfer formal to informal: {sentence}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "    outputs = model.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def openai_style_transfer(sentence, direction=\"informal_to_formal\", model_name=\"gpt-4o-mini\"):\n",
    "    if not openai.api_key:\n",
    "        return \"[OpenAI API key not set]\"\n",
    "    if direction == \"informal_to_formal\":\n",
    "        system_prompt = \"You are a helpful assistant that rewrites informal English sentences into formal English.\"\n",
    "        user_prompt = f\"Rewrite this sentence in a formal style: {sentence}\"\n",
    "    else:\n",
    "        system_prompt = \"You are a helpful assistant that rewrites formal English sentences into informal English.\"\n",
    "        user_prompt = f\"Rewrite this sentence in an informal style: {sentence}\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        max_tokens=128\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def bleu_scores(reference, prediction):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    scores = {}\n",
    "    for n in range(1, 5):\n",
    "        weights = tuple([1.0 / n] * n + [0.0] * (4 - n))\n",
    "        scores[f\"BLEU-{n}\"] = sentence_bleu([reference], prediction, weights=weights[:n], smoothing_function=smoothie)\n",
    "    return scores\n",
    "\n",
    "def llm_judge(original, t5_out, llm_out, direction):\n",
    "    prompt = f\"\"\"You are an expert in English style transfer. Given the following original sentence and two outputs from different models, judge which output is the best {direction.replace('_', ' ')} version. Explain your reasoning and give a score (1-10) for each output. Respond in no more than two lines.\\n\\nOriginal: {original}\\nFine-tuned T5: {t5_out}\\nGPT-4o Mini: {llm_out}\\n\"\"\"\n",
    "    if not openai.api_key:\n",
    "        return \"[OpenAI API key not set]\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful judge for style transfer outputs.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c5c61",
   "metadata": {},
   "source": [
    "## 5. Example Sentences\n",
    "\n",
    "Set up example sentences for informal-to-formal and formal-to-informal style transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9026a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences for both directions\n",
    "informal_example = \"yo, gimme the doc quick!\"\n",
    "formal_example = \"Could you please provide the document at your earliest convenience?\"\n",
    "\n",
    "examples = [\n",
    "    (informal_example, \"informal_to_formal\"),\n",
    "    (formal_example, \"formal_to_informal\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93091137",
   "metadata": {},
   "source": [
    "## 6. Run Style Transfer\n",
    "\n",
    "Apply both models to the example sentences and collect their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32733442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'yo, gimme the doc quick!',\n",
       "  'direction': 'informal_to_formal',\n",
       "  't5_out': 'You should see the doctor quickly.',\n",
       "  'llm_out': '[OpenAI API key not set]'},\n",
       " {'input': 'Could you please provide the document at your earliest convenience?',\n",
       "  'direction': 'formal_to_informal',\n",
       "  't5_out': 'Could you please provide the document at your earliest convenience?',\n",
       "  'llm_out': '[OpenAI API key not set]'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store results for each example\n",
    "results = []\n",
    "for sent, direction in examples:\n",
    "    t5_out = t5_style_transfer(sent, direction)\n",
    "    llm_out = openai_style_transfer(sent, direction)\n",
    "    results.append({\n",
    "        \"input\": sent,\n",
    "        \"direction\": direction,\n",
    "        \"t5_out\": t5_out,\n",
    "        \"llm_out\": llm_out\n",
    "    })\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ebe13",
   "metadata": {},
   "source": [
    "## 7. Evaluate with BLEU Scores\n",
    "\n",
    "Compute BLEU-1 to BLEU-4 scores for each model's output compared to the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a56d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'yo, gimme the doc quick!',\n",
       "  'direction': 'informal_to_formal',\n",
       "  't5_bleu': {'BLEU-1': 0.16666666666666669,\n",
       "   'BLEU-2': 0.07728215553472559,\n",
       "   'BLEU-3': 0.051142590811078435,\n",
       "   'BLEU-4': 0.03759340464156993},\n",
       "  'llm_bleu': {'BLEU-1': 0, 'BLEU-2': 0, 'BLEU-3': 0, 'BLEU-4': 0}},\n",
       " {'input': 'Could you please provide the document at your earliest convenience?',\n",
       "  'direction': 'formal_to_informal',\n",
       "  't5_bleu': {'BLEU-1': 1.0, 'BLEU-2': 1.0, 'BLEU-3': 1.0, 'BLEU-4': 1.0},\n",
       "  'llm_bleu': {'BLEU-1': 0, 'BLEU-2': 0, 'BLEU-3': 0, 'BLEU-4': 0}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU scores for each result\n",
    "bleu_results = []\n",
    "for r in results:\n",
    "    ref = r[\"input\"].split()\n",
    "    t5_bleu = bleu_scores(ref, r[\"t5_out\"].split())\n",
    "    llm_bleu = bleu_scores(ref, r[\"llm_out\"].split())\n",
    "    bleu_results.append({\n",
    "        \"input\": r[\"input\"],\n",
    "        \"direction\": r[\"direction\"],\n",
    "        \"t5_bleu\": t5_bleu,\n",
    "        \"llm_bleu\": llm_bleu\n",
    "    })\n",
    "bleu_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa95e3",
   "metadata": {},
   "source": [
    "## 8. LLM Judge Evaluation\n",
    "\n",
    "Let GPT-4o Mini act as a judge to compare the outputs and provide a score for tone and style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313c8df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'yo, gimme the doc quick!',\n",
       "  'direction': 'informal_to_formal',\n",
       "  'judge': '[OpenAI API key not set]'},\n",
       " {'input': 'Could you please provide the document at your earliest convenience?',\n",
       "  'direction': 'formal_to_informal',\n",
       "  'judge': '[OpenAI API key not set]'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Judge each pair using GPT-4o Mini\n",
    "judge_results = []\n",
    "for r in results:\n",
    "    judge = llm_judge(r[\"input\"], r[\"t5_out\"], r[\"llm_out\"], r[\"direction\"])\n",
    "    judge_results.append({\n",
    "        \"input\": r[\"input\"],\n",
    "        \"direction\": r[\"direction\"],\n",
    "        \"judge\": judge\n",
    "    })\n",
    "judge_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
